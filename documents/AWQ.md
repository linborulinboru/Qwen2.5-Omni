# Qwen2.5-Omni AWQ æœå‹™æ¶æ§‹æ–‡æª”

## æ¦‚è¿°

æœ¬æ–‡æª”è©³ç´°è¨˜éŒ„ Qwen2.5-Omni AWQ é‡åŒ–ç‰ˆæœ¬æœå‹™çš„æ‰€æœ‰æ¨¡å¡Šçµæ§‹ã€åŠŸèƒ½å’Œå·²çŸ¥å•é¡Œï¼Œç”¨æ–¼å¾ŒçºŒä»£ç¢¼é‡æ§‹åƒè€ƒã€‚

**ç‰ˆæœ¬**: AWQ é‡åŒ–ç‰ˆæœ¬
**æ–‡ä»¶**: `serve/qwen2_5_omni_awq.py`
**ç›®çš„**: éŸ³é »è½‰éŒ„ HTTP æœå‹™
**ç‹€æ…‹**: âŒ æ‰¹æ¬¡è™•ç†å­˜åœ¨å•é¡Œï¼Œç•¶å‰ä½¿ç”¨é€å€‹è™•ç†æ–¹å¼ï¼ˆä»ç„¡æ³•æ­£å¸¸å·¥ä½œï¼‰

---

## æ ¸å¿ƒä¾è³´é …

### ç³»çµ±ä¾è³´
```python
import io, os, sys, tempfile
import numpy as np
import torch
import importlib.util
import threading, uuid
from pathlib import Path
from datetime import datetime
from flask import Flask, request, jsonify, send_file
from argparse import ArgumentParser
from huggingface_hub import hf_hub_download
```

### AWQ é‡åŒ–ç›¸é—œ
```python
from awq.models.base import BaseAWQForCausalLM
from transformers import Qwen2_5OmniProcessor
from qwen_omni_utils import process_mm_info  # âš ï¸ å·²çŸ¥å•é¡Œ
```

### è‡ªå®šç¾©æ¨¡çµ„
```python
# ä½é¡¯å­˜æ¨¡å¼
from modeling_qwen2_5_omni_low_VRAM_mode import (
    Qwen2_5OmniDecoderLayer,
    Qwen2_5OmniForConditionalGeneration
)

# å…±ç”¨å·¥å…·
from common_utils import (
    OpenCCConverter,    # ç°¡ç¹è½‰æ›
    AudioProcessor,     # éŸ³é »è™•ç†
    IdleChecker,        # ç©ºé–’æª¢æ¸¬
    generate_srt        # SRTç”Ÿæˆ
)

from security import SecurityValidator, add_security_headers
```

---

## å…¨å±€é…ç½®

### Flask æ‡‰ç”¨
```python
app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 4 * 1024 * 1024 * 1024  # 4GB
```

### å…¨å±€è®Šé‡
| è®Šé‡ | é¡å‹ | ç”¨é€” |
|------|------|------|
| `model` | AWQ Model | é‡åŒ–æ¨¡å‹å¯¦ä¾‹ |
| `processor` | Qwen2_5OmniProcessor | æ–‡æœ¬/éŸ³é »è™•ç†å™¨ |
| `opencc_converter` | OpenCCConverter | ç°¡ç¹è½‰æ› |
| `model_lock` | Lock | æ¨¡å‹è¨ªå•é– |
| `processing_lock` | Lock | è«‹æ±‚åºåˆ—åŒ–é– |
| `idle_checker` | IdleChecker | ç©ºé–’ç›£æ§ |
| `job_status` | dict | ç•°æ­¥ä»»å‹™ç‹€æ…‹ |

### ç›®éŒ„çµæ§‹
```
inputs/   # ä¸Šå‚³æ–‡ä»¶
temp/     # è‡¨æ™‚éŸ³é »ç‰‡æ®µ
outputs/  # è½‰éŒ„çµæœ
```

---

## æ ¸å¿ƒæ¨¡å¡Š

### 1. æ¨¡å‹åŠ è¼‰

#### `replace_transformers_module()`
æ›¿æ› transformers æ¨¡çµ„ä»¥æ”¯æŒä½é¡¯å­˜æ¨¡å¼ã€‚

**å·¥ä½œåŸç†**:
1. åˆªé™¤æ¨™æº–æ¨¡çµ„: `del sys.modules['transformers.models.qwen2_5_omni.modeling_qwen2_5_omni']`
2. åŠ è¼‰è‡ªå®šç¾©æ¨¡çµ„: `low-VRAM-mode/modeling_qwen2_5_omni_low_VRAM_mode.py`
3. æ³¨å…¥ç³»çµ±: `sys.modules[original_mod_name] = new_mod`

#### `Qwen2_5_OmniAWQForConditionalGeneration`
AWQ é‡åŒ–æ¨¡å‹åŒ…è£é¡ã€‚

**é—œéµé…ç½®**:
```python
layer_type = "Qwen2_5OmniDecoderLayer"
max_seq_len_key = "max_position_embeddings"
modules_to_not_convert = ["visual"]  # è¦–è¦ºæ¨¡çµ„ä¸é‡åŒ–
```

**é—œéµæ–¹æ³•**:
- `get_model_layers()`: è¿”å›å¯é‡åŒ–å±¤
- `move_embed()`: ç§»å‹•åµŒå…¥å±¤åˆ° CUDA
- `get_layers_for_scaling()`: é…ç½®é‡åŒ–å±¤

#### `load_model_processor(checkpoint_path, flash_attn2, local_model)`
åŠ è¼‰æ¨¡å‹ä¸»æµç¨‹ã€‚

**æµç¨‹**:
```
1. replace_transformers_module()
2. åŠ è¼‰ AWQ é‡åŒ–æ¨¡å‹
   â”œâ”€ flash_attn2=True â†’ Flash Attention 2
   â””â”€ flash_attn2=False â†’ æ¨™æº– Attention
3. åŠ è¼‰ speaker dictionary (spk_dict.pt)
4. ç§»å‹•çµ„ä»¶åˆ° CUDA:
   â”œâ”€ embed_tokens
   â”œâ”€ visual
   â”œâ”€ audio_tower
   â””â”€ rotary_emb (æ‰€æœ‰å±¤)
5. åŠ è¼‰ processor
6. æ‰“å° GPU å…§å­˜ä½¿ç”¨
```

**GPU å…§å­˜åˆ†é…**: ~11GB (7B AWQ æ¨¡å‹)

#### `unload_model()`
å¸è¼‰æ¨¡å‹ä¸¦æ¸…ç† CUDA ç·©å­˜ã€‚ç”± `IdleChecker` åœ¨ç©ºé–’è¶…æ™‚å¾Œè‡ªå‹•è§¸ç™¼ã€‚

---

### 2. éŸ³é »è™•ç†

#### `transcribe_single_audio(audio_path, request_id, enable_s2t)` â­
æ ¸å¿ƒè½‰éŒ„å‡½æ•¸ã€‚

**ç•¶å‰å¯¦ç¾** (ä½¿ç”¨ librosa):
```python
# 1. æ§‹å»º prompt
system_prompt = "You are Qwen..."
user_prompt = "ä½ çš„å”¯ä¸€ä»»å‹™æ˜¯å°‡éŸ³é »å…§å®¹è½‰éŒ„ç‚ºæ–‡æœ¬..."

# 2. ä½¿ç”¨ librosa åŠ è¼‰éŸ³é »ï¼ˆç¹é process_mm_infoï¼‰
audio_array, sr = librosa.load(audio_path, sr=16000)

# 3. è½‰å–®è²é“
if audio_array.ndim > 1:
    audio_array = audio_array.mean(axis=1)

# 4. åŒ…è£æ ¼å¼
audios = [[audio_array]]

# 5. è™•ç†
inputs = processor(
    text=[text],
    audio=audios,
    return_tensors="pt"
).to(device).to(model.dtype)

# 6. ç”Ÿæˆ
text_ids = model.generate(**inputs, use_audio_in_video=True, ...)

# 7. è§£ç¢¼
response = processor.batch_decode(text_ids, ...)[0]

# 8. å¾Œè™•ç†
- ç§»é™¤ç”Ÿæˆæ¨™è¨˜
- ç§»é™¤çµæŸèª
- ç°¡ç¹è½‰æ›ï¼ˆoptionalï¼‰

# 9. æ¸…ç† CUDA ç·©å­˜
```

**å·²çŸ¥å•é¡Œ**:
- âŒ ä»ç„¶å‡ºç¾ `ValueError: axes don't match array`
- âŒ ç„¡æ³•æ­£å¸¸å·¥ä½œ
- âš ï¸ å•é¡Œå¯èƒ½åœ¨ processor å…§éƒ¨çš„ Whisper feature extractor

#### `transcribe_audio_batch(audio_paths, request_id)` âš ï¸ å·²å»¢æ£„
æ‰¹æ¬¡è™•ç†å·²æ”¾æ£„ï¼Œæ”¹ç‚ºå¾ªç’°èª¿ç”¨å–®å€‹è™•ç†ã€‚

**ç•¶å‰å¯¦ç¾**:
```python
results = []
for audio_path in audio_paths:
    try:
        result = transcribe_single_audio(audio_path, request_id)
        results.append(result)
    except Exception as e:
        results.append(f"[Error: {str(e)}]")
return results
```

**åŸå› **: processor æ‰¹æ¬¡è™•ç†æ•¸æ“šæ ¼å¼ä¸å…¼å®¹

#### `process_full_audio(audio_binary_data, original_filename)`
å®Œæ•´éŸ³é »è™•ç†æµç¨‹ã€‚

**æµç¨‹åœ–**:
```
1. ç”Ÿæˆ request_id: {timestamp}_{uuid}
2. ä¿å­˜ä¸Šå‚³æ–‡ä»¶ â†’ inputs/
3. è½‰æ› WAV â†’ temp/{request_id}_audio.wav
4. åˆ†å‰²éŸ³é » â†’ temp/{request_id}_segment_*.wav
   â””â”€ é»˜èªç‰‡æ®µé•·åº¦: 600ç§’
5. å‹•æ…‹èª¿æ•´æ‰¹æ¬¡å¤§å°:
   â”œâ”€ GPU å‰©é¤˜ < 8GB  â†’ batch_size = 2
   â”œâ”€ GPU å‰©é¤˜ < 16GB â†’ batch_size = 4
   â””â”€ GPU å‰©é¤˜ â‰¥ 16GB â†’ batch_size = 8
6. åˆ†æ‰¹è™•ç†:
   â”œâ”€ transcribe_audio_batch()
   â”œâ”€ æ¸…ç†å·²è™•ç†ç‰‡æ®µ
   â””â”€ æ¸…ç† CUDA ç·©å­˜
7. åˆä½µè½‰éŒ„çµæœ
8. ä¿å­˜ â†’ outputs/{timestamp}.txt
9. æ¸…ç†è‡¨æ™‚ WAV æ–‡ä»¶
```

**æ€§èƒ½ç›£æ§**:
- æ¯æ‰¹å¾Œæ‰“å° GPU å…§å­˜
- CUDA ç·©å­˜è‡ªå‹•æ¸…ç†

---

### 3. API ç«¯é»

#### `POST /transcribe`
è¿”å›æ–‡æœ¬æ–‡ä»¶ä¸‹è¼‰ã€‚

**è¼¸å…¥**:
- `file`: multipart/form-data
- æˆ– raw binary

**è¼¸å‡º**: `audio.txt` (application/octet-stream)

**å®‰å…¨**: æ–‡ä»¶åæ¶ˆæ¯’ã€å¤§å°é©—è­‰ã€é¡å‹é©—è­‰ã€é€Ÿç‡é™åˆ¶

#### `POST /transcribe/json`
è¿”å› JSON æ ¼å¼çµæœã€‚

**è¼¸å‡º**:
```json
{
  "status": "success",
  "transcription": "...",
  "output_file": "20251010123456.txt",
  "timestamp": "2025-10-10T12:34:56.789"
}
```

#### `POST /transcribe/srt`
è¿”å› SRT å­—å¹•æ–‡ä»¶ã€‚

**ç‰¹æ®Šé‚è¼¯**:
- ä¿ç•™æ™‚é–“æˆ³
- åŸºæ–¼ `segment_duration` è¨ˆç®—æ™‚é–“è»¸
- ä½¿ç”¨ `generate_srt()` ç”Ÿæˆæ ¼å¼

#### `POST /transcribe/async`
ç•°æ­¥è½‰éŒ„ï¼Œç«‹å³è¿”å› job_idã€‚

**æµç¨‹**:
```
1. é©—è­‰è¼¸å…¥
2. ç”Ÿæˆ job_id
3. å•Ÿå‹•å¾Œå°ç·šç¨‹
4. è¿”å› 202 Accepted
```

**è¿”å›**:
```json
{
  "status": "accepted",
  "job_id": "...",
  "message": "Use /status/<job_id> to check progress."
}
```

#### `GET /status/<job_id>`
æŸ¥è©¢ç•°æ­¥ä»»å‹™ç‹€æ…‹ã€‚

**ç‹€æ…‹**: `processing` | `completed` | `failed`

#### `GET /health`
å¥åº·æª¢æŸ¥ã€‚

**è¿”å›**:
```json
{
  "status": "ok",
  "model_loaded": true,
  "gpu_memory_allocated_gb": 11.05,
  "gpu_memory_reserved_gb": 12.54
}
```

---

### 4. å¾Œè™•ç†

#### æ–‡æœ¬æ¸…ç†
1. ç§»é™¤ç”Ÿæˆæ¨™è¨˜: `<|im_start|>assistant\n`
2. ç§»é™¤çµæŸèª:
   - "å¦‚æœä½ é‚„æœ‰å…¶ä»–é—œæ–¼éŸ³é »è½‰å¯«æˆ–è€…å…§å®¹ç†è§£çš„å•é¡Œ..."
   - "å¦‚æœä½ é‚„æœ‰å…¶ä»–é—œæ–¼é€™æ–¹é¢çš„å•é¡Œ..."
3. ç°¡ç¹è½‰æ› (OpenCC: s2t)

#### SRT ç”Ÿæˆ
æ ¼å¼:
```srt
1
00:00:00,000 --> 00:10:00,000
ç¬¬ä¸€æ®µè½‰éŒ„æ–‡æœ¬

2
00:10:00,000 --> 00:20:00,000
ç¬¬äºŒæ®µè½‰éŒ„æ–‡æœ¬
```

---

### 5. ä¸¦ç™¼æ§åˆ¶

#### é–æ©Ÿåˆ¶
| é– | ç”¨é€” |
|----|------|
| `model_lock` | ä¿è­·æ¨¡å‹åŠ è¼‰/å¸è¼‰ |
| `processing_lock` | åºåˆ—åŒ–è«‹æ±‚è™•ç† |
| `job_lock` | ä¿è­·ç•°æ­¥ä»»å‹™ç‹€æ…‹ |

#### IdleChecker
ç›£æ§ç©ºé–’æ™‚é–“ï¼Œè‡ªå‹•å¸è¼‰æ¨¡å‹ã€‚

**é…ç½®**:
- `idle_timeout`: 300ç§’
- `unload_callback`: `unload_model()`

**å·¥ä½œæ–¹å¼**:
```
å¾Œå°ç·šç¨‹æŒçºŒæª¢æŸ¥ â†’ è¶…æ™‚ â†’ å¸è¼‰æ¨¡å‹ â†’ ä¸‹æ¬¡è«‹æ±‚é‡æ–°åŠ è¼‰
```

---

## å‘½ä»¤è¡Œåƒæ•¸

| åƒæ•¸ | é»˜èªå€¼ | èªªæ˜ |
|------|--------|------|
| `--checkpoint-path` | Qwen/Qwen2.5-Omni-7B-AWQ | æ¨¡å‹è·¯å¾‘ |
| `--local-model` | False | ä½¿ç”¨æœ¬åœ°æ¨¡å‹ |
| `--flash-attn2` | False | Flash Attention 2 |
| `--segment-duration` | 600 | ç‰‡æ®µé•·åº¦(ç§’) |
| `--batch-size` | 4 | æ‰¹æ¬¡å¤§å° âš ï¸å·²å»¢æ£„ |
| `--max-new-tokens` | 8192 | æœ€å¤§ç”Ÿæˆ tokens |
| `--temperature` | 0.1 | æ¡æ¨£æº«åº¦ |
| `--repetition-penalty` | 1.1 | é‡è¤‡æ‡²ç½° |
| `--idle-timeout` | 300 | ç©ºé–’è¶…æ™‚(ç§’) |
| `--host` | 0.0.0.0 | ç›£è½åœ°å€ |
| `--port` | 5000 | æœå‹™ç«¯å£ |

---

## å·²çŸ¥å•é¡Œ

### âŒ æ‰¹æ¬¡è™•ç†å¤±æ•—
**éŒ¯èª¤**:
```
ValueError: axes don't match array
ValueError: operands could not be broadcast together
```

**ä½ç½®**: `transformers/models/whisper/feature_extraction_whisper.py:312`

**æ“ä½œ**: `input_features.transpose(2, 0, 1)`

**æ ¹æœ¬åŸå› **:
- `process_mm_info` è¿”å›æ ¼å¼èˆ‡ Whisper feature extractor ä¸å…¼å®¹
- å¯èƒ½æ˜¯ `qwen-omni-utils` æˆ– `transformers` ç‰ˆæœ¬å•é¡Œ

**å˜—è©¦éçš„ä¿®å¾©**:
1. âŒ æ‰‹å‹•å¡«å……éŸ³é »åˆ°ç›¸åŒé•·åº¦
2. âŒ å¤šè²é“è½‰å–®è²é“
3. âŒ èª¿æ•´æ•¸æ“šçµæ§‹ `[[audio1], [audio2], ...]`
4. âŒ ä½¿ç”¨ `librosa.load()` ç¹é `process_mm_info`
5. âŒ ç§»é™¤ `use_audio_in_video` åƒæ•¸

**ç•¶å‰ç‹€æ…‹**: âŒ å®Œå…¨ç„¡æ³•å·¥ä½œ

### âš ï¸ æ€§èƒ½å½±éŸ¿
- é€å€‹è™•ç†ç„¡æ³•åˆ©ç”¨ GPU æ‰¹æ¬¡å„ªå‹¢
- é•·éŸ³é »è™•ç†æ™‚é–“é¡¯è‘—å¢åŠ 

### âš ï¸ å…§å­˜ç®¡ç†
- éœ€è¦é »ç¹æ¸…ç† CUDA ç·©å­˜
- é•·æ™‚é–“é‹è¡Œå¯èƒ½å…§å­˜ç¢ç‰‡åŒ–

---

## é‡æ§‹å»ºè­°

### ğŸ”´ å„ªå…ˆç´š 1: ä¿®å¾©éŸ³é »è™•ç†
1. **æ·±å…¥èª¿æŸ¥ processor**:
   - æŸ¥çœ‹ `Qwen2_5OmniProcessor` æºä»£ç¢¼
   - ç¢ºèªæ­£ç¢ºéŸ³é »æ•¸æ“šçµæ§‹
   - æ¸¬è©¦ä¸åŒæ•¸æ“šæ ¼å¼

2. **æ›¿ä»£æ–¹æ¡ˆ**:
   - å®Œå…¨ç¹é `process_mm_info`
   - ç›´æ¥ç”¨ `librosa` + `numpy`
   - è‡ªå®šç¾©éŸ³é »é è™•ç†

3. **ç‰ˆæœ¬æ¸¬è©¦**:
   - ä¸åŒ `transformers` ç‰ˆæœ¬
   - ä¸åŒ `qwen-omni-utils` ç‰ˆæœ¬
   - é™ç´šåˆ°å·²çŸ¥å¯å·¥ä½œç‰ˆæœ¬

### ğŸŸ¡ å„ªå…ˆç´š 2: ä»£ç¢¼çµæ§‹
**åˆ†é›¢é—œæ³¨é»**:
```
audio_loader.py      # éŸ³é »åŠ è¼‰
model_handler.py     # æ¨¡å‹ç®¡ç†
api_routes.py        # Flask è·¯ç”±
config.py            # é…ç½®
transcriber.py       # è½‰éŒ„é‚è¼¯
```

**çµ±ä¸€éŒ¯èª¤è™•ç†**:
- è‡ªå®šç¾©ç•°å¸¸é¡
- çµ±ä¸€éŒ¯èª¤éŸ¿æ‡‰æ ¼å¼
- è©³ç´°éŒ¯èª¤æ—¥èªŒ

**æ”¹é€²ä¸¦ç™¼**:
- éšŠåˆ—ç³»çµ± (Celery, RQ)
- çœŸæ­£ç•°æ­¥è™•ç†
- æ”¯æŒä¸¦ç™¼è«‹æ±‚

### ğŸŸ¢ å„ªå…ˆç´š 3: åŠŸèƒ½å¢å¼·
1. é€²åº¦è¿½è¹¤ (WebSocket)
2. çµæœç·©å­˜
3. é ç†±æ¨¡å‹
4. éŸ³é »æµå¼è™•ç†
5. å¤š GPU æ”¯æŒ

---

## ä¾è³´çš„å¤–éƒ¨æ¨¡çµ„

### `common_utils.py`
- `OpenCCConverter`: ç°¡ç¹è½‰æ›
- `AudioProcessor`: ffmpeg éŸ³é »è½‰æ›èˆ‡åˆ†å‰²
- `IdleChecker`: ç©ºé–’ç›£æ§
- `generate_srt`: SRT ç”Ÿæˆ

### `security.py`
- `sanitize_filename()`: æ–‡ä»¶åæ¶ˆæ¯’
- `validate_file_size()`: å¤§å°é©—è­‰
- `validate_file_type()`: é¡å‹é©—è­‰
- `check_rate_limit()`: é€Ÿç‡é™åˆ¶
- `add_security_headers()`: å®‰å…¨æ¨™é ­

### `qwen_omni_utils`
```python
process_mm_info(messages, use_audio_in_video)
# è¿”å›: (audios, images, videos)
# âŒ å•é¡Œ: è¿”å›æ ¼å¼ä¸å…¼å®¹
```

---

## ç¶­è­·æ—¥èªŒ

### 2025-10-10
- âŒ æ‰¹æ¬¡è™•ç†å¤±æ•—ï¼Œæ”¹ç‚ºé€å€‹è™•ç†
- âŒ `process_mm_info` æ•¸æ“šæ ¼å¼å•é¡Œæœªè§£æ±º
- âŒ ä½¿ç”¨ `librosa` ç›´æ¥åŠ è¼‰ä»ç„¶å¤±æ•—
- âœ… å‰µå»ºæ­¤æ–‡æª”ç”¨æ–¼é‡æ§‹åƒè€ƒ
- âš ï¸ ç•¶å‰ç‰ˆæœ¬å®Œå…¨ç„¡æ³•å·¥ä½œ

**ä¸‹ä¸€æ­¥è¡Œå‹•**:
1. æŸ¥çœ‹ `Qwen2_5OmniProcessor` æºä»£ç¢¼
2. æ¸¬è©¦ä¸åŒ `transformers` ç‰ˆæœ¬
3. è€ƒæ…®å®Œå…¨é‡å¯«éŸ³é »è™•ç†æµç¨‹
4. å°‹æ‰¾å®˜æ–¹ç¤ºä¾‹ä»£ç¢¼åƒè€ƒ

---

## æŠ€è¡“è¦æ ¼

**é‹è¡Œç’°å¢ƒ**:
- Python 3.10
- PyTorch 2.8.0
- Transformers 4.52.3
- AWQ 0.2.9
- Librosa 0.11.0

**ç¡¬ä»¶éœ€æ±‚**:
- NVIDIA GPU (12GB+ VRAM)
- CUDA 12.8+
- 32GB+ RAM æ¨è–¦

**Dockeréƒ¨ç½²**:
- åŸºç¤é¡åƒ: `nvidia/cuda:12.8.0-devel-ubuntu22.04`
- ç«¯å£: 5000
- æ›è¼‰: `./app/serve`, `./app/inputs`, `./app/temp`, `./app/outputs`

---

## çµè«–

ç•¶å‰ AWQ æœå‹™å­˜åœ¨åš´é‡çš„éŸ³é »è™•ç†å•é¡Œï¼Œ**å®Œå…¨ç„¡æ³•æ­£å¸¸å·¥ä½œ**ã€‚æ‰¹æ¬¡è™•ç†å·²è¢«æ”¾æ£„ï¼Œä½†é€å€‹è™•ç†ä»ç„¶å¤±æ•—ã€‚

å•é¡Œæ ¹æºå¯èƒ½åœ¨æ–¼ï¼š
1. `process_mm_info` èˆ‡ `Qwen2_5OmniProcessor` ä¹‹é–“çš„æ•¸æ“šæ ¼å¼ä¸åŒ¹é…
2. Whisper feature extractor ç‰ˆæœ¬å…¼å®¹æ€§å•é¡Œ
3. AWQ é‡åŒ–å¾Œçš„æ¨¡å‹è™•ç†æµç¨‹èˆ‡æ¨™æº–ç‰ˆæœ¬ä¸åŒ
